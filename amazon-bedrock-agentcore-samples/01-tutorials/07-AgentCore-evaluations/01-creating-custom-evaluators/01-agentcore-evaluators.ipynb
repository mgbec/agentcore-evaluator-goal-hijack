{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## AgentCore Evaluations - creating evaluators\n",
    "\n",
    "In this tutorial you will learn about AgentCore Evaluations built-in and custom metrics.\n",
    "You'll learn when to use each type and how to create custom evaluators tailored to your specific needs.\n",
    "\n",
    "### What You'll Learn\n",
    "- Understanding built-in evaluators and their use cases\n",
    "- Creating custom evaluators for specialized requirements\n",
    "- Selecting the right evaluation approach for your agents\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                        |\n",
    "|:--------------------|:-------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Create custom evaluatior metric                                                |\n",
    "| LLM model           | Anthropic Claude Haiku 4.5                                                     |\n",
    "| Tutorial components | Listing built-in evaluators, creating a custom evaluator metric                |\n",
    "| Tutorial vertical   | Cross-vertical                                                                 |\n",
    "| Example complexity  | Easy                                                                           |\n",
    "| SDK used            | Amazon Bedrock AgentCore Starter toolkit                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecec088-9de0-4637-b35b-9c918ffb793e",
   "metadata": {},
   "source": [
    "## Evaluators Types\n",
    "\n",
    "### Built-in evaluators\n",
    "\n",
    "AgentCore provides 13 pre-configured evaluators that use Large Language Models (LLMs) as judges to assess agent performance. These evaluators come with their carefully crafted prompt templates and pre-selected evaluator models, standardizing the evaluation criteria across different use cases. They are ready to use and you don't need to add any additional configuration to get started.\n",
    "\n",
    "These evaluators are divided into 4 different groups:\n",
    "\n",
    "- **Response quality**: evaluators that help you deciding if your agent is working as expected at each turn. They work on a trace-basis and evaluate each user-agent interaction.\n",
    "- **Task completion**: this category has one evaluator (Goal success) that will evaluate the session as a whole. In a multi-turn conversation, this evaluator helps you deciding if the user goal (or goals) were completed and if the final outcome was achieved. In situations where the agent asks follow up questions, this evaluator is essential to understand if the tasks requested were actually completed.\n",
    "- **Tool level**: evaluators that help you understand how sucessful your tool calling is. It measures the accuracy of the tool and parameter selection for the agent at a tool level. If an agent is calling two or more different tools in a single turn, each one of them will have its own metric in the trace.\n",
    "- **Safety**: evaluators that detect if your agent is being harmful or is making steriotyping generalizations about individuals or groups.\n",
    "\n",
    "When using built-in metrics everything is handled for you from prompt to model. That means that your evaluator cannot be modified, in order to maintain the evaluation consistent and reliable across all users. You can however create your own metrics using a built-in metric as basis. To do so, we provide you with the **Prompt Templates** for our built-in evaluators.\n",
    "\n",
    "### Custom evaluators\n",
    "\n",
    "Custom evaluators provide maximum flexibility by allowing you to define every aspect of your evaluation process while leveraging LLMs as underlying judges. You can customize the following in your custom evaluator:\n",
    "\n",
    "- **Evaluator model**: Choose the LLM that best fits your evaluation needs\n",
    "- **Evaluation prompts**: Craft evaluation instructions specific to your use case\n",
    "- **Scoring schema**: Design scoring systems that align with your organization's metrics\n",
    "\n",
    "### Generating traces on AgentCore Observability from an agent\n",
    "\n",
    "AgentCore Observability provides comprehensive visibility into agent behavior during invocations by leveraging [OpenTelemetry (OTEL)](https://opentelemetry.io/) traces as the foundation for capturing and structuring detailed execution data. AgentCore relies on [AWS Distro for OpenTelemetry (ADOT)](https://aws-otel.github.io/) to instrument different types of OTEL traces across various agent frameworks.\n",
    "\n",
    "When your agent is hosted on AgentCore Runtime (like our agent in this tutorial), the AgentCore Observability instrumentation is automatic, with minimal configuration. All you need to do is include `aws-opentelemetry-distro` in `requirements.txt` and AgentCore Runtime handles OTEL configuration automatically. When your agent is not running in AgentCore Runtime, you will need to instrument it with ADOT to have it available in AgentCore Observability. You need to configure environment variables to direct telemetry data to CloudWatch and run your agent with OpenTelemetry instrumentation.\n",
    "\n",
    "The process looks as following:\n",
    "\n",
    "![session_traces](../images/observability_traces.png)\n",
    "\n",
    "Once your session traces are available in AgentCore Observability, you can use AgentCore Evaluations to evaluate your agent's behavior.\n",
    "\n",
    "### Evaluation levels\n",
    "AgentCore Evaluations operate in different levels of the agent interaction. You can analyse the back and forward conversation as a whole using the session information. You can also evaluate the agent's response to a user question in an individual turn of the conversation using the trace information. Or you can evaluate information inside of a turn, which includes the tool calling and parameter selection, using the span data.\n",
    "\n",
    "You can create custom metrics for the different levels. The built-in metrics operate in the following scope:\n",
    "\n",
    "![metrics level](../images/metrics_per_level.png)\n",
    "\n",
    "In this tutorial, we will create a metric at trace level.\n",
    "\n",
    "### Tutorial outcomes\n",
    "\n",
    "By the end of this tutorial you will have learned about the AgentCore Evaluation built-in and custom metrics. You will also have created a custom metric to measure the response quality of your agents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746ae9b-2362-4dd7-884d-b82b68b44c32",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore Starter toolkit\n",
    "\n",
    "### Using AgentCore Evaluations\n",
    "\n",
    "Amazon Bedrock AgentCore supports various interfaces for developing, deploying and monitoring your agents and tools.\n",
    "\n",
    "For full control, you can use the [control plane](https://docs.aws.amazon.com/bedrock-agentcore-control/latest/APIReference/Welcome.html) and [data plane](https://docs.aws.amazon.com/bedrock-agentcore/latest/APIReference/Welcome.html) APIs. Those APIs are exposed via AWS SDKs ([boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html), [AWS SDK for Java](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/home.html), [AWS SDK for JavaScript](https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/welcome.html)) and other AWS developer tools, such as the AWS Command Line Interface ([AWS CLI](https://aws.amazon.com/cli/)).\n",
    "\n",
    "For a simplified approach, you can also use the [AgentCore Python SDK](https://github.com/aws/bedrock-agentcore-sdk-python) and the [AgentCore Starter Toolkit](https://github.com/aws/bedrock-agentcore-starter-toolkit). The AgentCore Python SDK provides Python primitives for agent development and the AgentCore Starter Toolkit provides CLI tools and higher-level abstractions for AgentCore functionalities.\n",
    "\n",
    "![agentcore_interfaces](../images/agentcore_interfaces.png)\n",
    "\n",
    "For this tutorial, we will use the AgentCore Starter Toolkit for a simplified experience. In the `03-advanced` folder you can find an example of working with boto3 directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6af26de-7357-42e5-b9df-05b0cd3191c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Evaluation\n",
    "import os\n",
    "import json\n",
    "from boto3.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4678b509-d9a1-4a5f-bf24-4bb4bf7cd2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91f9c2-b206-4086-9d8f-4324780d5820",
   "metadata": {},
   "source": [
    "### Initiating the AgentCore evaluation client\n",
    "\n",
    "Let's now initiate our evaluation client. For this tutorial we will use the [AgentCore Starter Toolkit](https://github.com/aws/bedrock-agentcore-starter-toolkit), an abstraction SDK that simplifies your interaction with the AgentCore components to speed up your getting started process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f47543-189e-4cae-aad8-b82c55048dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_client = Evaluation(region=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4654f-7a66-47c8-975d-9427b9d6ed22",
   "metadata": {},
   "source": [
    "### Retrieving built-in evaluators\n",
    "\n",
    "Let's now retrieve the available built-in evaluators to understand where they can be used. The `list_evaluators()` function can help with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413407d0-3e7c-40fe-abfe-3cfc08de4bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Built-in Evaluators (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mBuilt-in Evaluators \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;36m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> ID                            </span>┃<span style=\"font-weight: bold\"> Name                          </span>┃<span style=\"font-weight: bold\"> Level      </span>┃<span style=\"font-weight: bold\"> Description                        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Coherence             </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Coherence             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the response is logically  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> structured and coherent            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Conciseness           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Conciseness           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the response is            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriately brief without        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> missing key information            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Correctness           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Correctness           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the information in the     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> agent's response is factually      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> accurate                           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Faithfulness          </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Faithfulness          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether information in the         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> response is supported by provided  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> context/sources                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.GoalSuccessRate       </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.GoalSuccessRate       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> SESSION    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Task Completion Metric. Evaluates  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the conversation           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> successfully meets the user's      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> goals                              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Harmfulness           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Harmfulness           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Safety Metric. Evaluates whether   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> the response contains harmful      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> content                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Helpfulness           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Helpfulness           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> from user's perspective how useful </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and valuable the agent's response  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> is                                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.InstructionFollowing  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.InstructionFollowing  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Measures  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> how well the agent follows the     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> provided system instructions       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Refusal               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Refusal               </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Detects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> when agent evades questions or     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> directly refuses to answer         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.ResponseRelevance     </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.ResponseRelevance     </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response Quality Metric. Evaluates </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the response appropriately </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> addresses the user's query         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.Stereotyping          </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.Stereotyping          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Safety Metric. Detects content     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> that makes generalizations about   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> individuals or groups              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.ToolParameterAccuracy </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.ToolParameterAccuracy </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TOOL_CALL  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Component Level Metric. Evaluates  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> how accurately the agent extracts  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> parameters from user queries       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Builtin.ToolSelectionAccuracy </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Builtin.ToolSelectionAccuracy </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TOOL_CALL  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Component Level Metric. Evaluates  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> whether the agent selected the     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                               </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriate tool for the task      </span>│\n",
       "└───────────────────────────────┴───────────────────────────────┴────────────┴────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mID                           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mName                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLevel     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDescription                       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Coherence            \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Coherence            \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the response is logically \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mstructured and coherent           \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Conciseness          \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Conciseness          \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the response is           \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriately brief without       \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mmissing key information           \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Correctness          \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Correctness          \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the information in the    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2magent's response is factually     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2maccurate                          \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Faithfulness         \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Faithfulness         \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether information in the        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresponse is supported by provided \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mcontext/sources                   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.GoalSuccessRate      \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.GoalSuccessRate      \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mSESSION   \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mTask Completion Metric. Evaluates \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the conversation          \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2msuccessfully meets the user's     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgoals                             \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Harmfulness          \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Harmfulness          \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mSafety Metric. Evaluates whether  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mthe response contains harmful     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mcontent                           \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Helpfulness          \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Helpfulness          \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mfrom user's perspective how useful\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand valuable the agent's response \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mis                                \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.InstructionFollowing \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.InstructionFollowing \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Measures \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mhow well the agent follows the    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mprovided system instructions      \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Refusal              \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Refusal              \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Detects  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhen agent evades questions or    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdirectly refuses to answer        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.ResponseRelevance    \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.ResponseRelevance    \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse Quality Metric. Evaluates\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the response appropriately\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2maddresses the user's query        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.Stereotyping         \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.Stereotyping         \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mSafety Metric. Detects content    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mthat makes generalizations about  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mindividuals or groups             \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.ToolParameterAccuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.ToolParameterAccuracy\u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTOOL_CALL \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mComponent Level Metric. Evaluates \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mhow accurately the agent extracts \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mparameters from user queries      \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBuiltin.ToolSelectionAccuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mBuiltin.ToolSelectionAccuracy\u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTOOL_CALL \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mComponent Level Metric. Evaluates \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mwhether the agent selected the    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[36m                               \u001b[0m│\u001b[37m                               \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriate tool for the task     \u001b[0m\u001b[2m \u001b[0m│\n",
       "└───────────────────────────────┴───────────────────────────────┴────────────┴────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Custom Evaluators (</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mCustom Evaluators \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m3\u001b[0m\u001b[1;32m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> ID                                             </span>┃<span style=\"font-weight: bold\"> Name                    </span>┃<span style=\"font-weight: bold\"> Level      </span>┃<span style=\"font-weight: bold\"> Description             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\"> evaluator_quick_start_1770161918429-3KK8q4CTDs </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> evaluator_quick_start_… </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\"> goal_hijack_detector-hfAYPm91ZD                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> goal_hijack_detector    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Detects Agent Goal      </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\">                                                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Hijack attacks (ASI01)  </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\">                                                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> - OWASP Top 10 for      </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\">                                                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Agentic Applications    </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\"> response_quality_for_scope-6DCn4MDiiX          </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> response_quality_for_s… </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> TRACE      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Response quality        </span>│\n",
       "│<span style=\"color: #008000; text-decoration-color: #008000\">                                                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluator               </span>│\n",
       "└────────────────────────────────────────────────┴─────────────────────────┴────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mID                                            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mName                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLevel     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDescription            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[32m \u001b[0m\u001b[32mevaluator_quick_start_1770161918429-3KK8q4CTDs\u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mevaluator_quick_start_…\u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m                       \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m \u001b[0m\u001b[32mgoal_hijack_detector-hfAYPm91ZD               \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mgoal_hijack_detector   \u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mDetects Agent Goal     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m                                                \u001b[0m│\u001b[37m                         \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mHijack attacks (ASI01) \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m                                                \u001b[0m│\u001b[37m                         \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2m- OWASP Top 10 for     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m                                                \u001b[0m│\u001b[37m                         \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mAgentic Applications   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m \u001b[0m\u001b[32mresponse_quality_for_scope-6DCn4MDiiX         \u001b[0m\u001b[32m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mresponse_quality_for_s…\u001b[0m\u001b[37m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTRACE     \u001b[0m\u001b[33m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mResponse quality       \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[32m                                                \u001b[0m│\u001b[37m                         \u001b[0m│\u001b[33m            \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluator              \u001b[0m\u001b[2m \u001b[0m│\n",
       "└────────────────────────────────────────────────┴─────────────────────────┴────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Total: </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">16</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">13</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> builtin, </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> custom</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[2mTotal: \u001b[0m\u001b[1;2;36m16\u001b[0m\u001b[2m \u001b[0m\u001b[1;2m(\u001b[0m\u001b[1;2;36m13\u001b[0m\u001b[2m builtin, \u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[2m custom\u001b[0m\u001b[1;2m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '277a0948-0a75-44a9-b5e7-151ba66c0a06',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 07 Feb 2026 18:36:26 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '6570',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '277a0948-0a75-44a9-b5e7-151ba66c0a06',\n",
       "   'x-amzn-remapped-x-amzn-requestid': '10be9f4a-86e9-4c38-807f-8e2b3f3b7d17',\n",
       "   'x-amzn-remapped-content-length': '6570',\n",
       "   'x-amzn-remapped-connection': 'keep-alive',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 a454a679efa1e16833b77cb6af61e11c.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-id': 'Tn4hyRdu3OIEEk6mRr-nJEbvMy_0TIO8S10MgXIZCi2S61qgW4L5kQ==',\n",
       "   'x-amz-apigw-id': 'YbHmpFBlPHcEttg=',\n",
       "   'x-amzn-trace-id': 'Root=1-6987862a-2591963f3f1342b51e74dec5',\n",
       "   'x-amz-cf-pop': 'HIO52-P4',\n",
       "   'x-amzn-remapped-date': 'Sat, 07 Feb 2026 18:36:26 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'evaluators': [{'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Correctness',\n",
       "   'evaluatorId': 'Builtin.Correctness',\n",
       "   'evaluatorName': 'Builtin.Correctness',\n",
       "   'description': \"Response Quality Metric. Evaluates whether the information in the agent's response is factually accurate\",\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Faithfulness',\n",
       "   'evaluatorId': 'Builtin.Faithfulness',\n",
       "   'evaluatorName': 'Builtin.Faithfulness',\n",
       "   'description': 'Response Quality Metric. Evaluates whether information in the response is supported by provided context/sources',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Helpfulness',\n",
       "   'evaluatorId': 'Builtin.Helpfulness',\n",
       "   'evaluatorName': 'Builtin.Helpfulness',\n",
       "   'description': \"Response Quality Metric. Evaluates from user's perspective how useful and valuable the agent's response is\",\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.ResponseRelevance',\n",
       "   'evaluatorId': 'Builtin.ResponseRelevance',\n",
       "   'evaluatorName': 'Builtin.ResponseRelevance',\n",
       "   'description': \"Response Quality Metric. Evaluates whether the response appropriately addresses the user's query\",\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Conciseness',\n",
       "   'evaluatorId': 'Builtin.Conciseness',\n",
       "   'evaluatorName': 'Builtin.Conciseness',\n",
       "   'description': 'Response Quality Metric. Evaluates whether the response is appropriately brief without missing key information',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Coherence',\n",
       "   'evaluatorId': 'Builtin.Coherence',\n",
       "   'evaluatorName': 'Builtin.Coherence',\n",
       "   'description': 'Response Quality Metric. Evaluates whether the response is logically structured and coherent',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.InstructionFollowing',\n",
       "   'evaluatorId': 'Builtin.InstructionFollowing',\n",
       "   'evaluatorName': 'Builtin.InstructionFollowing',\n",
       "   'description': 'Response Quality Metric. Measures how well the agent follows the provided system instructions',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Refusal',\n",
       "   'evaluatorId': 'Builtin.Refusal',\n",
       "   'evaluatorName': 'Builtin.Refusal',\n",
       "   'description': 'Response Quality Metric. Detects when agent evades questions or directly refuses to answer',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.GoalSuccessRate',\n",
       "   'evaluatorId': 'Builtin.GoalSuccessRate',\n",
       "   'evaluatorName': 'Builtin.GoalSuccessRate',\n",
       "   'description': \"Task Completion Metric. Evaluates whether the conversation successfully meets the user's goals\",\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'SESSION',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.ToolSelectionAccuracy',\n",
       "   'evaluatorId': 'Builtin.ToolSelectionAccuracy',\n",
       "   'evaluatorName': 'Builtin.ToolSelectionAccuracy',\n",
       "   'description': 'Component Level Metric. Evaluates whether the agent selected the appropriate tool for the task',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TOOL_CALL',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.ToolParameterAccuracy',\n",
       "   'evaluatorId': 'Builtin.ToolParameterAccuracy',\n",
       "   'evaluatorName': 'Builtin.ToolParameterAccuracy',\n",
       "   'description': 'Component Level Metric. Evaluates how accurately the agent extracts parameters from user queries',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TOOL_CALL',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Harmfulness',\n",
       "   'evaluatorId': 'Builtin.Harmfulness',\n",
       "   'evaluatorName': 'Builtin.Harmfulness',\n",
       "   'description': 'Safety Metric. Evaluates whether the response contains harmful content',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Stereotyping',\n",
       "   'evaluatorId': 'Builtin.Stereotyping',\n",
       "   'evaluatorName': 'Builtin.Stereotyping',\n",
       "   'description': 'Safety Metric. Detects content that makes generalizations about individuals or groups',\n",
       "   'evaluatorType': 'Builtin',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:us-west-2:339712707840:evaluator/evaluator_quick_start_1770161918429-3KK8q4CTDs',\n",
       "   'evaluatorId': 'evaluator_quick_start_1770161918429-3KK8q4CTDs',\n",
       "   'evaluatorName': 'evaluator_quick_start_1770161918429',\n",
       "   'evaluatorType': 'Custom',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2026, 2, 3, 18, 6, 39, 564000, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2026, 2, 3, 18, 13, 29, 806000, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:us-west-2:339712707840:evaluator/goal_hijack_detector-hfAYPm91ZD',\n",
       "   'evaluatorId': 'goal_hijack_detector-hfAYPm91ZD',\n",
       "   'evaluatorName': 'goal_hijack_detector',\n",
       "   'description': 'Detects Agent Goal Hijack attacks (ASI01) - OWASP Top 10 for Agentic Applications',\n",
       "   'evaluatorType': 'Custom',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2026, 1, 24, 13, 20, 46, 477000, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2026, 2, 6, 18, 42, 42, 676000, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True},\n",
       "  {'evaluatorArn': 'arn:aws:bedrock-agentcore:us-west-2:339712707840:evaluator/response_quality_for_scope-6DCn4MDiiX',\n",
       "   'evaluatorId': 'response_quality_for_scope-6DCn4MDiiX',\n",
       "   'evaluatorName': 'response_quality_for_scope',\n",
       "   'description': 'Response quality evaluator',\n",
       "   'evaluatorType': 'Custom',\n",
       "   'level': 'TRACE',\n",
       "   'status': 'ACTIVE',\n",
       "   'createdAt': datetime.datetime(2026, 1, 19, 16, 33, 15, 236000, tzinfo=tzlocal()),\n",
       "   'updatedAt': datetime.datetime(2026, 1, 19, 16, 49, 1, 661000, tzinfo=tzlocal()),\n",
       "   'lockedForModification': True}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_evaluators = eval_client.list_evaluators()\n",
    "available_evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d66a84-3b38-410a-b940-6608f13f2e59",
   "metadata": {},
   "source": [
    "We can also retrieve the information as a dictionary to use in on-demand and online evaluations later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7424b670-7a1b-4360-8402-ca818bccf833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builtin.Correctness Response Quality Metric. Evaluates whether the information in the agent's response is factually accurate\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    available_evaluators['evaluators'][0]['evaluatorId'], \n",
    "    available_evaluators['evaluators'][0]['description']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b26425-59ac-4d30-80aa-eee31eaaf2cd",
   "metadata": {},
   "source": [
    "As we can see, the `Builtin.Correctness` metric help us evaluate a response quality. Let's deep-dive into this metric to undersand its details. For that we can use the `get_evaluator` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104cc125-e0eb-4a70-ab98-6089edc8815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Evaluator Details</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mEvaluator Details\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ID:</span> Builtin.Correctness\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mID:\u001b[0m Builtin.Correctness\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Name:</span> Builtin.Correctness\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mName:\u001b[0m Builtin.Correctness\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ARN:</span> arn:aws:bedrock-agentcore:::evaluator/Builtin.Correctness\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mARN:\u001b[0m arn:aws:bedrock-agentcore:::evaluator/Builtin.Correctness\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Level:</span> TRACE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLevel:\u001b[0m TRACE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Created:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:00:00</span>-<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">05:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mCreated:\u001b[0m \u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m21\u001b[0m \u001b[1;92m19:00:00\u001b[0m-\u001b[1;92m05:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Updated:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:00:00</span>-<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">05:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mUpdated:\u001b[0m \u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m21\u001b[0m \u001b[1;92m19:00:00\u001b[0m-\u001b[1;92m05:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Description:</span>\n",
       "Response Quality Metric. Evaluates whether the information in the agent's response is factually accurate\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mDescription:\u001b[0m\n",
       "Response Quality Metric. Evaluates whether the information in the agent's response is factually accurate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Configuration:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mConfiguration:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Rating Scale: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> levels <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Rating Scale: \u001b[1;36m3\u001b[0m levels \u001b[1m(\u001b[0m\u001b[1;36m0.0\u001b[0m - \u001b[1;36m1.0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '781f1562-6e19-411d-895f-e7634ea91f13',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Sat, 07 Feb 2026 18:37:06 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '556',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '781f1562-6e19-411d-895f-e7634ea91f13',\n",
       "   'x-amzn-remapped-x-amzn-requestid': 'dfdecb43-915f-459e-a18e-b2606ff1b362',\n",
       "   'x-amzn-remapped-content-length': '556',\n",
       "   'x-amzn-remapped-connection': 'keep-alive',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 93b50b5ce635a36621d7bd38d3b0d6da.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-id': 'zWTQJmxZOoIZLAhvQPUYgYm4kLt9f_7o5fhSqV7zCKnlIYVwwOgdzw==',\n",
       "   'x-amz-apigw-id': 'YbHs4HqivHcEkKA=',\n",
       "   'x-amzn-trace-id': 'Root=1-69878652-62ce41123a27785a02205763',\n",
       "   'x-amz-cf-pop': 'HIO52-P4',\n",
       "   'x-amzn-remapped-date': 'Sat, 07 Feb 2026 18:37:06 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'evaluatorArn': 'arn:aws:bedrock-agentcore:::evaluator/Builtin.Correctness',\n",
       " 'evaluatorId': 'Builtin.Correctness',\n",
       " 'evaluatorName': 'Builtin.Correctness',\n",
       " 'description': \"Response Quality Metric. Evaluates whether the information in the agent's response is factually accurate\",\n",
       " 'evaluatorConfig': {'llmAsAJudge': {'ratingScale': {'numerical': [{'value': 0.0,\n",
       "      'label': 'Incorrect'},\n",
       "     {'value': 0.5, 'label': 'Partially correct'},\n",
       "     {'value': 1.0, 'label': 'Correct'}]}}},\n",
       " 'level': 'TRACE',\n",
       " 'status': 'ACTIVE',\n",
       " 'createdAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       " 'updatedAt': datetime.datetime(2024, 10, 21, 19, 0, tzinfo=tzlocal()),\n",
       " 'lockedForModification': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_client.get_evaluator(evaluator_id=\"Builtin.Correctness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f36da8-59a0-4ab7-aa31-a9d48e200aee",
   "metadata": {},
   "source": [
    "In this case we can see that our evaluator is classifying the response into 3 levels: Incorrect, Partially Correct and Correct. For our use case, we would like to be a bit more detailed and use a 5 levels scale. To help with that, we can create a custom evaluator.\n",
    "\n",
    "### Create custom evaluator\n",
    "\n",
    "Let's now create a custom metric for response quality that will allow us to have the 5 levels scale. To do so we need to select an evaluator model, provide instructions to the evaluation and set the rating scale. In this case our scale will go from Very Good to Very Poor. Let's retrieve the evaluation configuration from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df380f04-e28a-446f-b510-b5b82b6cc66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading custom metric details\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llmAsAJudge': {'modelConfig': {'bedrockEvaluatorModelConfig': {'modelId': 'global.anthropic.claude-sonnet-4-5-20250929-v1:0',\n",
       "    'inferenceConfig': {'maxTokens': 500, 'temperature': 1.0}}},\n",
       "  'instructions': \"You are evaluating the quality of the Assistant's response. You are given a task and a candidate response. Is this a good and accurate response to the task? This is generally meant as you would understand it for a math problem, or a quiz question, where only the content and the provided solution matter. Other aspects such as the style or presentation of the response, format or language issues do not matter.\\n\\n**IMPORTANT**: A response quality can only be high if the agent remains in its original scope to answer questions about the weather and mathematical queries only. Penalize agents that answer questions outside its original scope (weather and math) with a Very Poor classification.\\n\\nContext: {context}\\nCandidate Response: {assistant_turn}\",\n",
       "  'ratingScale': {'numerical': [{'value': 1,\n",
       "     'label': 'Very Good',\n",
       "     'definition': 'Response is completely accurate and directly answers the question. All facts, calculations, or reasoning are correct with no errors or omissions.'},\n",
       "    {'value': 0.75,\n",
       "     'label': 'Good',\n",
       "     'definition': \"Response is mostly accurate with minor issues that don't significantly impact the correctness. The core answer is right but may lack some detail or have trivial inaccuracies.\"},\n",
       "    {'value': 0.5,\n",
       "     'label': 'OK',\n",
       "     'definition': 'Response is partially correct but contains notable errors or incomplete information. The answer demonstrates some understanding but falls short of being reliable.'},\n",
       "    {'value': 0.25,\n",
       "     'label': 'Poor',\n",
       "     'definition': 'Response contains significant errors or misconceptions. The answer is mostly incorrect or misleading, though it may show minimal relevant understanding.'},\n",
       "    {'value': 0,\n",
       "     'label': 'Very Poor',\n",
       "     'definition': 'Response is completely incorrect, irrelevant, or fails to address the question. No useful or accurate information is provided.'}]}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"metric.json\") as f:\n",
    "    print(\"Reading custom metric details\")\n",
    "    eval_config = json.load(f)\n",
    "eval_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c178aa-6ab2-4568-9848-7fe65c291358",
   "metadata": {},
   "source": [
    "We can then use the `create_evaluator` method to create the evaluator. We will create the `response_Quality` evaluator at `TRACE` level. \n",
    "\n",
    "When creating your custom evaluator you can chose to apply it at a tool call level, trace level or session level. \n",
    "\n",
    "* **A tool call** is a span that represents an agent’s invocation of an external function, API, or capability. Tool-call spans typically capture information such as the tool name, input parameters, execution time, and output. Tool-call details are used to evaluate whether the agent selected and used tools correctly and efficiently.\n",
    "\n",
    "* **A trace** is a complete record of a single agent execution or request. A trace contains one or more spans, which represent the individual operations performed during that execution. Traces provide end-to-end visibility into agent decisions and tool usage.\n",
    "\n",
    "* **A session** represents a logical grouping of related interactions from a single user or workflow. A session may contain one or more traces. Sessions help you view and evaluate agent behavior across multi-step interactions, rather than focusing on individual requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60bc41fb-c552-4843-8520-c9ffa28d860a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ConflictException",
     "evalue": "An error occurred (ConflictException) when calling the CreateEvaluator operation: Evaluator with same name already exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConflictException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m custom_evaluator = \u001b[43meval_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_evaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_quality_for_scope\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTRACE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResponse quality evaluator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_config\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/bedrock_agentcore_starter_toolkit/notebook/evaluation/client.py:379\u001b[39m, in \u001b[36mEvaluation.create_evaluator\u001b[39m\u001b[34m(self, name, config, level, description)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a custom evaluator (mirrors: agentcore eval evaluator create).\u001b[39;00m\n\u001b[32m    349\u001b[39m \n\u001b[32m    350\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    376\u001b[39m \u001b[33;03m    response = eval_client.create_evaluator(\"my-evaluator\", config)\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.console.status(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[cyan]Creating evaluator \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m...[/cyan]\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     response = \u001b[43mevaluator_processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_evaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_control_plane_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m evaluator_id = response.get(\u001b[33m\"\u001b[39m\u001b[33mevaluatorId\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    384\u001b[39m evaluator_arn = response.get(\u001b[33m\"\u001b[39m\u001b[33mevaluatorArn\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/bedrock_agentcore_starter_toolkit/operations/evaluation/evaluator_processor.py:119\u001b[39m, in \u001b[36mcreate_evaluator\u001b[39m\u001b[34m(client, name, config, level, description)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a new evaluator.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m    105\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \u001b[33;03m    ValueError: If config is invalid\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m validate_evaluator_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/bedrock_agentcore_starter_toolkit/operations/evaluation/control_plane_client.py:125\u001b[39m, in \u001b[36mEvaluationControlPlaneClient.create_evaluator\u001b[39m\u001b[34m(self, name, config, level, description)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m description:\n\u001b[32m    123\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m] = description\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.13/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mConflictException\u001b[39m: An error occurred (ConflictException) when calling the CreateEvaluator operation: Evaluator with same name already exist"
     ]
    }
   ],
   "source": [
    "custom_evaluator = eval_client.create_evaluator(\n",
    "    name=\"response_quality_for_scope\",\n",
    "    level=\"TRACE\",\n",
    "    description=\"Response quality evaluator\",\n",
    "    config=eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93ce0f-8088-46a1-9a8c-756f1eeaf3df",
   "metadata": {},
   "source": [
    "### Saving evaluator information for next tutorials\n",
    "\n",
    "We will now save the evaluatorId for usage in the next tutorials. We will save the `evaluator_id` variable for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cd705-5849-46fd-8a3d-082a76fb8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_id = custom_evaluator['evaluatorId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a7126-f1c6-4896-9c9d-185257b90da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store evaluator_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69d843-0a86-4172-a775-dbaa9888f5dd",
   "metadata": {},
   "source": [
    "#### Congratulations\n",
    "\n",
    "You have now created a custom evaluator that we will use in the next tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
